{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import string\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Load data: read in csv as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protests = []\n",
    "\n",
    "# open file\n",
    "with open('protests.csv', 'rU') as csvfile: \n",
    "    \n",
    "    # create a reader\n",
    "    reader = csv.DictReader(csvfile) \n",
    "    \n",
    "    # loop through rows\n",
    "    for row in reader: \n",
    "        \n",
    "        # append each row to the list\n",
    "        protests.append(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(protests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'PUBLICATION', 'TITLE', 'COUNTRY', 'LENGTH', 'TEXT', 'DATE']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = protests[1].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Write function that passes two arguments: article and city\n",
    "Function will search the text of the article for the city of interest, identify its index, and then search for the root words \"protest\" or its synonym \"manifest\" (short for manifestação, and permutations thereof) within 30 words of the city name.\n",
    "\n",
    "#####Note: \n",
    "Previous trial-and-error of earlier versions of this function revealed that articles in which there was any punctuation attached to the city name, the function would not detect it as one of the \"search terms.\" In other words, an article that said \"manifestantes protestaram em Curitiba, mas estavam pacíficos\" would not detect \"protest\" near \"Curitiba\" because of the comma. The same was true with compound city names. Hence the effort to modify the function to tokenize the articles at the beginning, remove punctuation, and concatenate compound names.\n",
    "\n",
    "These were the special cases I needed to account for:\n",
    "\n",
    "| Condition       | Example          | Worked?  |\n",
    "|------------- |-------------| -----|\n",
    "| accent      | \"Brasília\" | yes |\n",
    "| punctuation      | \"Rio.\"      | no    |\n",
    "| compound | \"São Paulo\"      |    no |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_cities(article, city):\n",
    "    \n",
    "    #this removes punctuation\n",
    "    article = article.translate(None, string.punctuation)\n",
    "    \n",
    "    #this removes endline characters\n",
    "    article = article.translate(None, \"\\n\")\n",
    "    \n",
    "    #this concatenates compound names with an underscore\n",
    "    article = article.replace(\"São Paulo\", \"São_Paulo\")\n",
    "    article = article.replace(\"Belo Horizonte\", \"Belo_Horizonte\")\n",
    "    article = article.replace(\"Porto Alegre\", \"Porto_Alegre\")\n",
    "    article = article.replace(\"Rio de Janeiro\", \"Rio\")\n",
    "    \n",
    "    text = article.split()\n",
    "    if city in text:\n",
    "        takeIndex = text.index(city)\n",
    "        wc = len(text)\n",
    "        if takeIndex > 30 and takeIndex < wc - 30:\n",
    "            subset = ' '.join(text[takeIndex-30:takeIndex+30])\n",
    "        elif takeIndex < 30 and takeIndex < wc - 30:\n",
    "            subset = ' '.join(text[:takeIndex+30])\n",
    "        elif takeIndex > 30 and takeIndex > wc - 30:\n",
    "            subset = ' '.join(text[takeIndex-30:])\n",
    "\n",
    "        if 'protest'or 'manifest' in subset:\n",
    "            return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. Call function on each of the 10 cities\n",
    "This is a nested loop that loops over all of the articles ('TEXT') from inside of the dictionaries in protest. For each article, loop over all of the 10 cities I want to search for. Each time, it adds an key to the dictionary that contains the results from that search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_search_for = [\"Rio\", \"Brasília\", \"Belo_Horizonte\", \"Curitiba\", \"Salvador\",\\\n",
    "                 \"São_Paulo\", \"Porto_Alegre\", \"Fortaleza\", \"Recife\", \"Campinas\"]\n",
    "\n",
    "for i in protests:\n",
    "    for j in to_search_for:\n",
    "        i[j] = query_cities(i['TEXT'], j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7. Write CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'PUBLICATION', 'Salvador', 'TITLE', 'COUNTRY', 'Belo_Horizonte', 'Campinas', 'Bras\\xc3\\xadlia', 'Rio', 'LENGTH', 'Fortaleza', 'S\\xc3\\xa3o_Paulo', 'TEXT', 'DATE', 'Curitiba', 'Recife', 'Porto_Alegre']\n"
     ]
    }
   ],
   "source": [
    "keys = protests[0].keys()\n",
    "print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writing the rest\n",
    "with open('protest_cities.csv', 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(protests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
